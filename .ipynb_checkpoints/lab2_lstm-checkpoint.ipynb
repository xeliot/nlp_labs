{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "import os\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import seaborn as sns\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Pre-trained word vectors Glove zip\n",
    "http://nlp.stanford.edu/data/glove.6B.zip  \n",
    "Unzip 6B zip file from Downloads  \n",
    "Copy \"glove.6B.300d.txt\" from unzipped folder  \n",
    "Create folder named \"data\" and paste copied text file into \"data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Pre-trained word vectors from Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_file = datapath(os.getcwd()+\"/data/glove.6B.300d.txt\")\n",
    "word2vec_glove_file = get_tmpfile(os.getcwd()+\"/data/glove.6B.300d.word2vec.txt\")\n",
    "glove2word2vec(glove_file, word2vec_glove_file)\n",
    "model = KeyedVectors.load_word2vec_format(word2vec_glove_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine word vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.29353  ,  0.33247  , -0.047372 , -0.12247  ,  0.071956 ,\n",
       "       -0.23408  , -0.06238  , -0.0037192, -0.39462  , -0.69411  ,\n",
       "        0.36731  , -0.12141  , -0.044485 , -0.15268  ,  0.34864  ,\n",
       "        0.22926  ,  0.54361  ,  0.25215  ,  0.097972 , -0.087305 ,\n",
       "        0.87058  , -0.12211  , -0.079825 ,  0.28712  , -0.68563  ,\n",
       "       -0.27265  ,  0.22056  , -0.75752  ,  0.56293  ,  0.091377 ,\n",
       "       -0.71004  , -0.3142   , -0.56826  , -0.26684  , -0.60102  ,\n",
       "        0.26959  , -0.17992  ,  0.10701  , -0.57858  ,  0.38161  ,\n",
       "       -0.67127  ,  0.10927  ,  0.079426 ,  0.022372 , -0.081147 ,\n",
       "        0.011182 ,  0.67089  , -0.19094  , -0.33676  , -0.48471  ,\n",
       "       -0.35406  , -0.15209  ,  0.44503  ,  0.46385  ,  0.38409  ,\n",
       "        0.045081 , -0.59079  ,  0.21763  ,  0.38576  , -0.44567  ,\n",
       "        0.009332 ,  0.442    ,  0.097062 ,  0.38005  , -0.11881  ,\n",
       "       -0.42718  , -0.31005  , -0.025058 ,  0.12689  , -0.13468  ,\n",
       "        0.11976  ,  0.76253  ,  0.2524   , -0.26934  ,  0.068629 ,\n",
       "       -0.10071  ,  0.011066 , -0.18532  ,  0.44983  , -0.57507  ,\n",
       "        0.12278  , -0.064878 ,  0.044456 , -0.020999 , -0.069838 ,\n",
       "       -0.47329  , -0.43074  ,  0.39158  , -0.047815 , -0.93659  ,\n",
       "       -0.55128  , -0.1422   , -0.15829  ,  0.15623  ,  0.070461 ,\n",
       "        0.19892  ,  0.18942  , -0.19339  , -0.46594  , -0.028825 ,\n",
       "        0.0056752, -0.0054038,  0.43144  ,  0.12257  , -0.2611   ,\n",
       "        0.04847  ,  0.32244  , -0.31064  , -0.10559  ,  0.97954  ,\n",
       "        0.069626 , -0.023187 , -0.86293  ,  0.48273  ,  0.23649  ,\n",
       "       -0.0034704, -0.18932  ,  0.18588  ,  0.023211 , -0.30643  ,\n",
       "       -0.35717  ,  0.19605  , -0.1584   , -0.0058626,  0.35248  ,\n",
       "        0.036053 , -0.53933  ,  0.49435  ,  0.45332  , -0.18477  ,\n",
       "        0.040648 , -0.094517 , -0.07116  ,  0.74005  , -0.11465  ,\n",
       "       -0.26916  ,  0.089765 , -0.25205  , -0.21469  , -0.38847  ,\n",
       "        0.32509  ,  0.25773  , -0.51764  , -0.38457  ,  0.028254 ,\n",
       "       -0.21232  , -0.27311  ,  0.69178  , -0.37681  ,  0.14241  ,\n",
       "       -0.24926  ,  0.40314  , -0.052916 ,  0.07684  ,  0.2135   ,\n",
       "        0.10921  ,  0.049658 ,  0.02093  ,  0.11953  ,  0.28648  ,\n",
       "        0.87791  ,  0.085838 ,  0.31983  ,  0.51856  , -0.22628  ,\n",
       "        0.12402  ,  0.48805  ,  0.22111  , -0.52021  ,  0.0025106,\n",
       "       -0.13305  , -0.052565 ,  0.32744  ,  0.64985  ,  0.072426 ,\n",
       "       -0.52743  , -0.20913  , -0.27897  , -0.10834  , -0.10103  ,\n",
       "        0.15299  , -0.36681  ,  0.082445 ,  0.1739   , -0.28099  ,\n",
       "       -0.069136 ,  0.7895   ,  0.060571 ,  0.38693  , -0.16495  ,\n",
       "       -0.21801  ,  0.33288  , -0.44568  , -0.49892  , -0.34438  ,\n",
       "       -0.035606 , -0.24239  , -0.4747   , -0.17254  ,  0.071349 ,\n",
       "        1.4091   ,  0.46166  ,  0.46546  , -0.30979  ,  0.37203  ,\n",
       "        0.47897  , -0.28872  , -0.65515  , -0.13629  , -0.14287  ,\n",
       "       -0.04843  , -0.12786  ,  0.18941  , -0.037051 ,  0.59471  ,\n",
       "       -0.0051618, -0.0086009, -0.33313  ,  0.288    , -0.058965 ,\n",
       "       -0.67275  ,  0.15544  ,  0.074187 , -0.36441  , -0.021285 ,\n",
       "       -0.065337 ,  0.13827  ,  0.008395 , -0.041113 ,  0.29401  ,\n",
       "       -0.10344  , -0.052371 , -0.63084  ,  0.16311  ,  0.052826 ,\n",
       "       -0.021797 , -0.28115  , -0.078361 , -0.38124  ,  0.078089 ,\n",
       "        0.38411  , -0.34629  , -0.4322   ,  0.091731 , -0.67867  ,\n",
       "       -0.041138 , -0.53981  ,  0.10678  ,  0.03343  ,  0.81396  ,\n",
       "       -0.19448  ,  0.026248 , -0.14215  ,  0.2954   ,  0.62738  ,\n",
       "        0.26499  ,  0.6191   , -0.04113  ,  0.12301  ,  0.3158   ,\n",
       "        0.10698  ,  0.023654 , -0.41355  ,  0.034852 ,  0.21361  ,\n",
       "        0.045834 ,  0.053415 , -0.36421  ,  0.19707  ,  0.50916  ,\n",
       "       -0.1949   , -0.18788  , -0.24449  , -0.63397  , -0.23125  ,\n",
       "       -0.18823  , -1.0601   ,  0.47794  , -1.0102   ,  0.24604  ,\n",
       "       -0.4876   ,  0.79146  , -0.11047  , -0.21762  , -0.6178   ,\n",
       "        0.27815  , -0.098169 , -0.063205 ,  0.066069 , -0.69305  ,\n",
       "       -0.25928  ,  0.44591  , -0.64198  , -0.33084  , -0.30154  ,\n",
       "       -0.56359  ,  0.60501  , -0.09673  ,  0.44444  ,  0.22007  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['cat']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity between two words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hor/anaconda3/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6998663"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity(\"man\", \"woman\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector arithmetics of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hor/anaconda3/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('daughter', 0.8807988166809082),\n",
       " ('wife', 0.7806316018104553),\n",
       " ('daughters', 0.709545373916626)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['mother', 'son'], negative=['father'], topn=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch 20 News Groups Data\n",
    "4 categories\n",
    " - gun politics\n",
    " - christianity\n",
    " - computer graphics\n",
    " - science medical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['comp.graphics', 'sci.med', 'soc.religion.christian', 'talk.politics.guns']\n",
      "2323\n",
      "2323\n"
     ]
    }
   ],
   "source": [
    "categories = ['talk.politics.guns', 'soc.religion.christian', 'comp.graphics', 'sci.med']\n",
    "twenty_train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)\n",
    "print(twenty_train.target_names) # news categories used\n",
    "print(len(twenty_train.data))\n",
    "print(len(twenty_train.filenames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define LSTM network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, hidden_size, layer_dim=1):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.layer_dim = layer_dim\n",
    "        self.lstm1 = nn.LSTM(input_size=300, hidden_size=hidden_size, num_layers=layer_dim, batch_first=True, bidirectional=True, dropout=0.4)\n",
    "        self.fc1 = nn.Linear(hidden_size*2, 20) # hidden_size *2 because of bidirectional\n",
    "        self.fc2 = nn.Linear(20, 20)\n",
    "        self.fc3 = nn.Linear(20, 4)\n",
    "        self.dropout = nn.Dropout(p=0.4)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        out, (hn, cn) = self.lstm1(inputs)\n",
    "        hn_flat = torch.cat((hn[0], hn[1]), dim=1)\n",
    "        out = F.relu(self.fc1(hn_flat))\n",
    "        out = self.dropout(out)\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "    \n",
    "net = LSTM(hidden_size=20, layer_dim=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add spaces before and after punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "puncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£', \n",
    " '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', \n",
    " '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', \n",
    " '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', \n",
    " '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]\n",
    "\n",
    "def clean_text(x):\n",
    "    x = str(x)\n",
    "    for punct in puncts:\n",
    "        if punct in x:\n",
    "            x = x.replace(punct, f' {punct} ')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of preprocessing our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['from', ':', 'petch', '@', 'gvg47', '.', 'gvg', '.', 'tek', '.', 'com', '(', 'chuck', 'petch', ')', 'subject', ':', 'daily', 'verse', 'organization', ':', 'grass', 'valley', 'group', ',', 'grass', 'valley', ',', 'ca', 'lines', ':', '4', 'for', 'whoever', 'does', 'the', 'will', 'of', 'my', 'father', 'in', 'heaven', 'is', 'my', 'brother', 'and', 'sister', 'and', 'mother', '.', '\"', 'matthew', '12', ':', '50']\n"
     ]
    }
   ],
   "source": [
    "print(clean_text(twenty_train.data[2]).replace('\\n', ' ').lower().split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize sequence length distribution to determine appropriate bin separations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pos_word_length_dist = []\n",
    "for article in twenty_train.data:\n",
    "    cleaned_article = clean_text(article).replace('\\n', ' ').lower().split()\n",
    "    pos_word_length_dist.append(len(cleaned_article))\n",
    "\n",
    "plt.hist(pos_word_length_dist, bins=400)\n",
    "plt.xlim(0, 1000)\n",
    "#sns.distplot(pos_word_length_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse data into bins to feed into model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(data, target):\n",
    "    random_seed = np.random.randint(low=len(data), size=len(data))\n",
    "    shuffled_data = data[random_seed]\n",
    "    shuffled_target = target[random_seed]\n",
    "    return (shuffled_data, shuffled_target)\n",
    "\n",
    "# Sequence is a 2D vector, A sentence is a sequence of words represented as word vector\n",
    "def fix_sequence_size(sequence, size):\n",
    "    if len(sequence) == size:\n",
    "        return sequence\n",
    "    elif len(sequence) > size:\n",
    "        # Truncate\n",
    "        return sequence[:size]\n",
    "    elif len(sequence) < size:\n",
    "        # Pad zeros\n",
    "        word_vec_size = sequence[0].size\n",
    "        return np.concatenate((sequence, np.zeros((int(size-len(sequence)), word_vec_size), dtype=float)))\n",
    "\n",
    "def organize_into_bins(documents, target, num_bins):\n",
    "    bin_input = []\n",
    "    bin_target = []\n",
    "    batch_lengths = []\n",
    "    for i in range(num_bins):\n",
    "        bin_input.append([])\n",
    "        bin_target.append([])\n",
    "        batch_lengths.append([])\n",
    "    \n",
    "    for i in range(0, len(documents)):\n",
    "        if len(documents[i]) <= 1000:\n",
    "            index = len(documents[i]) // 100\n",
    "            batch_lengths[index].append(len(documents[i]))\n",
    "        else:\n",
    "            batch_lengths[10].append(len(documents[i]))\n",
    "            \n",
    "    for i in range(0, len(documents)):\n",
    "        if len(documents[i]) <= 1000:\n",
    "            index = len(documents[i]) // 100\n",
    "            # within a bin, keep word length of documents the same e.g. 80 percentile of the word length\n",
    "            # pad documents less than the 80 percentile length of bin and truncate documents above the 80 percentile length of bin\n",
    "            cutoff = math.floor(np.percentile(np.array(batch_lengths[index]), q=80))\n",
    "            bin_input[index].append(fix_sequence_size(documents[i], cutoff))\n",
    "            bin_target[index].append(target[i])\n",
    "        else:\n",
    "            bin_input[10].append(fix_sequence_size(documents[i], 1000))\n",
    "            bin_target[10].append(target[i])\n",
    "    return(bin_input, bin_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess raw data and place into appropriate bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORD_VECTOR_SIZE=300\n",
    "data = []\n",
    "target = []\n",
    "for i in range(0, len(twenty_train.data)):\n",
    "    article_vector = []\n",
    "    cleaned_article = clean_text(twenty_train.data[i]).replace('\\n', ' ').lower().split()\n",
    "    for word in cleaned_article:\n",
    "        try:\n",
    "            article_vector.append(model[word])\n",
    "        except KeyError:\n",
    "            article_vector.append(np.zeros(WORD_VECTOR_SIZE, dtype=float))\n",
    "    data.append(article_vector)\n",
    "    target.append(twenty_train.target[i])\n",
    "\n",
    "(data, target) = shuffle(data=np.array(data), target=np.array(target))\n",
    "input_test = data[:300]\n",
    "target_test = target[:300]\n",
    "input_validation = data[300:600]\n",
    "target_validation = target[300:600]\n",
    "input_train = data[600:]\n",
    "target_train = target[600:]\n",
    "(bin_input, bin_target) = organize_into_bins(documents=input_train, target=target_train, num_bins=11)\n",
    "(bin_input_validation, bin_target_validation) = organize_into_bins(documents=input_validation, target=target_validation, num_bins=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55, 775, 300)\n",
      "(55,)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(bin_input[7]).shape)\n",
    "print(np.array(bin_target[7]).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Loss: 1.4142707694660535 |  Validation Loss: 1.409272475676103\n",
      "Running Loss: 1.3824527588757602 |  Validation Loss: 1.3743045221675525\n",
      "Running Loss: 1.3690865148197522 |  Validation Loss: 1.3516438657587224\n",
      "Running Loss: 1.3644776994531804 |  Validation Loss: 1.3412442749196833\n",
      "Running Loss: 1.3323088884353638 |  Validation Loss: 1.3174712332812222\n",
      "Running Loss: 1.318755648352883 |  Validation Loss: 1.2951932061802258\n",
      "Running Loss: 1.2542007077823987 |  Validation Loss: 1.2439989826895974\n",
      "Running Loss: 1.1180026097731157 |  Validation Loss: 1.102182854305614\n",
      "Running Loss: 1.0836339863863858 |  Validation Loss: 0.9979432821273804\n",
      "Running Loss: 0.9779805270108309 |  Validation Loss: 0.9215782691131938\n",
      "Running Loss: 0.8619511777704413 |  Validation Loss: 0.9749049165032126\n",
      "Running Loss: 0.8371564583344893 |  Validation Loss: 0.9821085333824158\n",
      "Running Loss: 0.8146158185872164 |  Validation Loss: 0.7343922257423401\n",
      "Running Loss: 0.6901520897041667 |  Validation Loss: 0.6776220107620413\n",
      "Running Loss: 0.6765391447327354 |  Validation Loss: 0.5918249216946688\n",
      "Running Loss: 0.5198619772087444 |  Validation Loss: 0.5994635502045805\n",
      "Running Loss: 0.49343878572637384 |  Validation Loss: 0.6713019799102437\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-f30817a71c87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m#print(outputs.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.005)\n",
    "\n",
    "for epoch in range(35):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    running_validation_loss = 0.0\n",
    "    for i in range(0, len(bin_input)):\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        net.train()\n",
    "        \n",
    "        batch_input = np.array(bin_input[i])\n",
    "        batch_target = np.array(bin_target[i])\n",
    "        batch_input = torch.from_numpy(batch_input)\n",
    "        batch_input = batch_input.type(torch.float)\n",
    "        batch_target = torch.from_numpy(batch_target)\n",
    "        batch_target = batch_target.type(torch.long)\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        outputs = net(batch_input)\n",
    "        #print(outputs.shape)\n",
    "        loss = criterion(outputs, batch_target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            net.eval()\n",
    "            batch_input_validation = np.array(bin_input_validation[i])\n",
    "            batch_target_validation = np.array(bin_target_validation[i])\n",
    "            batch_input_validation = torch.from_numpy(batch_input_validation)\n",
    "            batch_input_validation = batch_input_validation.type(torch.float)\n",
    "            batch_target_validation = torch.from_numpy(batch_target_validation)\n",
    "            batch_target_validation = batch_target_validation.type(torch.long)\n",
    "\n",
    "            validation_outputs = net(batch_input_validation)\n",
    "            validation_loss = criterion(validation_outputs, batch_target_validation)\n",
    "            net.train() \n",
    "            running_validation_loss += validation_loss.item()\n",
    "\n",
    "    print(\"Running Loss: \" + str((running_loss / len(bin_input))) + \" |  Validation Loss: \" + str((running_validation_loss / len(bin_input))))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "\n",
    "def predict_from_vector(review_vector):\n",
    "    review_tensor = torch.tensor(review_vector, dtype=torch.float)\n",
    "    review_tensor = review_tensor.view(1, len(review_vector), 300)\n",
    "    prediction = net(review_tensor)\n",
    "    return torch.argmax(prediction.view(prediction.size(1)))\n",
    "\n",
    "def class_report(input_test, ground_truth):\n",
    "    prediction = []\n",
    "    for document_vector in input_test:\n",
    "        prediction.append(predict_from_vector(document_vector))\n",
    "    prediction = np.array(prediction)\n",
    "    ground_truth = np.array(ground_truth)\n",
    "    print(confusion_matrix(ground_truth, prediction))  \n",
    "    print(classification_report(ground_truth, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[52  5 11  6]\n",
      " [ 6 61  1 18]\n",
      " [ 8  0 53  2]\n",
      " [ 4  9  4 60]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.70      0.72        74\n",
      "           1       0.81      0.71      0.76        86\n",
      "           2       0.77      0.84      0.80        63\n",
      "           3       0.70      0.78      0.74        77\n",
      "\n",
      "   micro avg       0.75      0.75      0.75       300\n",
      "   macro avg       0.76      0.76      0.75       300\n",
      "weighted avg       0.76      0.75      0.75       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_report(input_test=input_test, ground_truth=target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
