{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import errno\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55938\n"
     ]
    }
   ],
   "source": [
    "path = os.getcwd()+\"/data/text_data/train/pos/*.txt\"\n",
    "files = glob.glob(path)\n",
    "counter = 0\n",
    "corpus = \"\"\n",
    "\n",
    "for name in files:\n",
    "    try:\n",
    "        with open(name, 'r') as f:\n",
    "            if counter < 50:\n",
    "                #print(review)\n",
    "                counter += 1\n",
    "                review = f.read().replace('\\n', '').replace('<br /><br />', ' ').replace('.', ' .').replace('!', ' !').replace('?', ' ?')\n",
    "                #review = \"i ate a dog with some ketchup . it was very tasty . then i ate a cat with some mustard . it was also very tasty .\"\n",
    "                review = review.lower()\n",
    "                #print(review)\n",
    "                corpus += review\n",
    "                corpus += \" \"\n",
    "                #review = review.split()\n",
    "                #review = ['<start>'] + review + ['<end>']\n",
    "    except IOError as exc:\n",
    "        if exc.errno != errno.EISDIR:\n",
    "            raise\n",
    "            \n",
    "    \n",
    "print(len(corpus))\n",
    "#print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars:  62\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(corpus))) # getting all unique chars\n",
    "num_unique_chars = len(chars)\n",
    "print('total chars: ', num_unique_chars)\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(corpus) - maxlen, step):\n",
    "    sentences.append(corpus[i: i + maxlen])\n",
    "    next_chars.append(corpus[i + maxlen])\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences)), dtype=np.float)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i] = char_indices[next_chars[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18633, 40, 62)\n",
      "(18633,)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " ...\n",
      " [False False False ... False False False]\n",
      " [ True False False ... False False False]\n",
      " [False False False ... False False False]]\n",
      "52.0\n"
     ]
    }
   ],
   "source": [
    "print(x[0])\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([52,  0, 36,  ..., 40, 40,  1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(y).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, hidden_size, layer_dim=1):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.layer_dim = layer_dim\n",
    "        self.lstm1 = nn.LSTM(input_size=num_unique_chars, hidden_size=hidden_size, num_layers=layer_dim, batch_first=True, bidirectional=True, dropout=0.4)\n",
    "        self.fc1 = nn.Linear(hidden_size*2, 50) # hidden_size *2 because of bidirectional\n",
    "        self.fc2 = nn.Linear(50, 50)\n",
    "        self.fc3 = nn.Linear(50, num_unique_chars)\n",
    "        self.dropout = nn.Dropout(p=0.4)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        out, (hn, cn) = self.lstm1(inputs)\n",
    "        hn_flat = torch.cat((hn[0], hn[1]), dim=1)\n",
    "        out = F.relu(self.fc1(hn_flat))\n",
    "        out = self.dropout(out)\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "    \n",
    "net = LSTM(hidden_size=50, layer_dim=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  tensor(4.1473, grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(4.0936, grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(4.0186, grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(3.8520, grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(3.4723, grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(3.4550, grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(3.2876, grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(3.1688, grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(3.1586, grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(3.1572, grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(3.1506, grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(3.1328, grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(3.1059, grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(3.0853, grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(3.0676, grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(3.0588, grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(3.0517, grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(3.0384, grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(3.0330, grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(3.0318, grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(3.0318, grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(3.0262, grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(3.0251, grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(3.0185, grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(3.0142, grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(3.0101, grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(3.0047, grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(3.0015, grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(2.9973, grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(2.9937, grad_fn=<NllLossBackward>)\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    inputs = torch.from_numpy(x).float()\n",
    "    target = torch.from_numpy(y).long()\n",
    "    \n",
    "    outputs = net(inputs)\n",
    "    #print(outputs.shape)\n",
    "    #print(target.shape)\n",
    "    #print(outputs)\n",
    "    #print(target)\n",
    "    loss = criterion(outputs, target)\n",
    "    \n",
    "    print(\"loss: \", loss)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_next_char(sentence):\n",
    "    #sentence is 40 characters\n",
    "    sentence_trunc = [sentence[-40:]]\n",
    "    x = np.zeros((len(sentence), len(sentence_trunc), len(chars)), dtype=np.bool)\n",
    "    #y = np.zeros((len(sentences)), dtype=np.float)\n",
    "    for i, sentence in enumerate(sentence_trunc):\n",
    "        for t, char in enumerate(sentence):\n",
    "            x[i, t, char_indices[char]] = 1\n",
    "        #y[i] = char_indices[next_chars[i]]\n",
    "    \n",
    "    inputs = torch.from_numpy(x).float()\n",
    "    outputs = net(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "of three teenage girls at Bromwell High.\n"
     ]
    }
   ],
   "source": [
    "sentence = \"If you like adult comedy cartoons, like South Park, then this is nearly a similar format about the small adventures of three teenage girls at Bromwell High.\"\n",
    "print(sentence[-40:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 156 is out of bounds for axis 0 with size 156",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-27d0b8140ab9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerate_next_char\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-94e58c63edc9>\u001b[0m in \u001b[0;36mgenerate_next_char\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchar_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnext_chars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 156 is out of bounds for axis 0 with size 156"
     ]
    }
   ],
   "source": [
    "generate_next_char(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
