{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words NLP Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import 20 News Groups dataset from scikitlearn\n",
    "Focusing on 4 of the news categories:  \n",
    "- Gun Politics\n",
    "- Christian\n",
    "- Graphics\n",
    "- Science Medical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['talk.politics.guns', 'soc.religion.christian', 'comp.graphics', 'sci.med']\n",
    "twenty_train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['comp.graphics', 'sci.med', 'soc.religion.christian', 'talk.politics.guns']\n",
      "2323\n",
      "2323\n"
     ]
    }
   ],
   "source": [
    "print(twenty_train.target_names) # news categories used\n",
    "print(len(twenty_train.data))\n",
    "print(len(twenty_train.filenames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample Input from Imported Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: Petch@gvg47.gvg.tek.com (Chuck Petch)\n",
      "Subject: Daily Verse\n",
      "Organization: Grass Valley Group, Grass Valley, CA\n",
      "Lines: 4\n",
      "\n",
      "For whoever does the will of my Father in heaven is my brother and sister\n",
      "and mother.\" \n",
      "\n",
      "Matthew 12:50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print(\"\\n\".join(twenty_train.data[0].split(\"\\n\")[:3]))\n",
    "print(\"\\n\".join(twenty_train.data[2].split(\"\\n\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample Label from Imported Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soc.religion.christian\n"
     ]
    }
   ],
   "source": [
    "print(twenty_train.target_names[twenty_train.target[2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build tf_idf Document Term Matrix\n",
    "Count Vectorizer: stores counts of vocabulary within a document; strips non-ascii characters, lowercases all characters, removes common stop words in english dictionary, includes n-grams feature lengths of up to 3  \n",
    "TfidfTransformer: transforms count vector into a normalized tfidf representation  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(strip_accents='ascii', lowercase=True, stop_words='english', ngram_range=(1, 3))\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "x_train_counts = count_vect.fit_transform(twenty_train.data)\n",
    "x_train_tfidf = tfidf_transformer.fit_transform(x_train_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shape of Document Term Matrix;\n",
    "Try changing the ngram_range; see how the number of columsn in the document term matrix changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2323, 580346)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Logistic Regression Model to predict news category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf = LogisticRegression()\n",
    "text_clf.fit(x_train_tfidf, twenty_train.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test our gradient boosted classifier model on sample texts\n",
    "Try putting some other string texts into \"docs_new\" and see which category our model predicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'God is love' => soc.religion.christian\n",
      "'OpenGL on the GPU is fast' => comp.graphics\n",
      "'Gun violence is a real problem' => talk.politics.guns\n",
      "'Doctors cure critical brain tumor in patient' => sci.med\n",
      "'Space Radiation Doesnt Seem to Be Causing Astronauts to Die from Cancer, Study Finds' => sci.med\n"
     ]
    }
   ],
   "source": [
    "docs_new = ['God is love', 'OpenGL on the GPU is fast', 'Gun violence is a real problem', 'Doctors cure critical brain tumor in patient', 'Space Radiation Doesnt Seem to Be Causing Astronauts to Die from Cancer, Study Finds']\n",
    "X_new_counts = count_vect.transform(docs_new) # only use transform because transformers are already fitted to dataset\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts) # only use transform because transformers are already fitted to dataset\n",
    "\n",
    "predicted = text_clf.predict(X_new_tfidf)\n",
    "\n",
    "for doc, category in zip(docs_new, predicted):\n",
    "    print('%r => %s' % (doc, twenty_train.target_names[category]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate our logistic regression model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.936005171299289"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_test = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=42)\n",
    "docs_test = twenty_test.data\n",
    "test_counts = count_vect.transform(docs_test)\n",
    "test_tfidf = tfidf_transformer.transform(test_counts)\n",
    "predicted = text_clf.predict(test_tfidf)\n",
    "np.mean(predicted == twenty_test.target) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Gradient Boosted Decision Tree to predict news category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "              n_iter_no_change=None, presort='auto', random_state=None,\n",
       "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: instead of using Logistic Regression, train a \"GradientBoostingClassifier\" with parameter n_estimators=10\n",
    "# Lookup sklearn.ensemble.GradientBoostingClassifier\n",
    "## text_clf = ...(n_estimators=...)\n",
    "\n",
    "\n",
    "# TODO: fit text classifier to training data; pass in document term matrix \"x_train_tfidf\" and corresponding labels \"twenty_train.target\"\n",
    "## text_clf.fit(..., ...)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test our gradient boosted classifier model on sample texts\n",
    "Try putting some other string texts into \"docs_new\" and see which category our model predicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'God is love' => soc.religion.christian\n",
      "'OpenGL on the GPU is fast' => sci.med\n",
      "'Gun violence is a real problem' => talk.politics.guns\n",
      "'Doctors cure critical brain tumor in patient' => sci.med\n",
      "'Space Radiation Doesnt Seem to Be Causing Astronauts to Die from Cancer, Study Finds' => sci.med\n"
     ]
    }
   ],
   "source": [
    "docs_new = ['God is love', 'OpenGL on the GPU is fast', 'Gun violence is a real problem', 'Doctors cure critical brain tumor in patient', 'Space Radiation Doesnt Seem to Be Causing Astronauts to Die from Cancer, Study Finds']\n",
    "X_new_counts = count_vect.transform(docs_new) # only use transform because transformers are already fitted to dataset\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts) # only use transform because transformers are already fitted to dataset\n",
    "\n",
    "predicted = text_clf.predict(X_new_tfidf)\n",
    "\n",
    "for doc, category in zip(docs_new, predicted):\n",
    "    print('%r => %s' % (doc, twenty_train.target_names[category]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate our gradient boosted classifier on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8332255979314803"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_test = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=42)\n",
    "docs_test = twenty_test.data\n",
    "test_counts = count_vect.transform(docs_test)\n",
    "test_tfidf = tfidf_transformer.transform(test_counts)\n",
    "predicted = text_clf.predict(test_tfidf)\n",
    "np.mean(predicted == twenty_test.target) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying out other news groups:\n",
    "We only used 4 of the news groups! You can change which news groups we want to use to train our models at the beginning of this notebook in the import step.  \n",
    "Here are all 20 of the available news groups from the dataset.  \n",
    "<img src=\"./screenshots/20news_groups.png\" alt=\"drawing\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying out more models:\n",
    "Here's a couple of other models available in scikit-learn you can try out in your spare time:  \n",
    "- Naive Bayes\n",
    "- Decision Tree\n",
    "- Random Forest\n",
    "- XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
