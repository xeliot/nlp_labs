{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import errno\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55938\n"
     ]
    }
   ],
   "source": [
    "path = os.getcwd()+\"/data/text_data/train/pos/*.txt\"\n",
    "files = glob.glob(path)\n",
    "counter = 0\n",
    "corpus = \"\"\n",
    "\n",
    "for name in files:\n",
    "    try:\n",
    "        with open(name, 'r') as f:\n",
    "            if counter < 50:\n",
    "                #print(review)\n",
    "                counter += 1\n",
    "                review = f.read().replace('\\n', '').replace('<br /><br />', ' ').replace('.', ' .').replace('!', ' !').replace('?', ' ?')\n",
    "                #review = \"i ate a dog with some ketchup . it was very tasty . then i ate a cat with some mustard . it was also very tasty .\"\n",
    "                review = review.lower()\n",
    "                #print(review)\n",
    "                corpus += review\n",
    "                corpus += \" \"\n",
    "                #review = review.split()\n",
    "                #review = ['<start>'] + review + ['<end>']\n",
    "    except IOError as exc:\n",
    "        if exc.errno != errno.EISDIR:\n",
    "            raise\n",
    "            \n",
    "    \n",
    "print(len(corpus))\n",
    "#print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars:  62\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(corpus))) # getting all unique chars\n",
    "num_unique_chars = len(chars)\n",
    "print('total chars: ', num_unique_chars)\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for a movie that gets no respect there s\n",
      "or a movie that gets no respect there su\n",
      "(1398, 40, 62)\n",
      "(1398, 40)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor i in range(0, len(sentences)):\\n    sentence = sentences[i]\\n    for t in range()\\n\\nfor i, sentence in enumerate(sentences):\\n    for t, char in enumerate(sentence):\\n        x[i, t, char_indices[char]] = 1\\n    y[i] = char_indices[next_chars[i]]\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen = 40\n",
    "step = 40\n",
    "sentences = []\n",
    "sentences_shifted = []\n",
    "next_chars = []\n",
    "for i in range(0, len(corpus) - maxlen, step):\n",
    "    sentences.append(corpus[i: i + maxlen])\n",
    "    sentences_shifted.append(corpus[i+1: i+1+maxlen])\n",
    "    next_chars.append(corpus[i + maxlen])\n",
    "    \n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.float)\n",
    "y = np.zeros((len(sentences), maxlen), dtype=np.float)\n",
    "\n",
    "print(sentences[0])\n",
    "print(sentences_shifted[0])\n",
    "\n",
    "for i in range(0, len(sentences)):\n",
    "    sentence = sentences[i]\n",
    "    sentence_shifted = sentences_shifted[i]\n",
    "    for t in range(0, len(sentence)):\n",
    "        char = sentence[t]\n",
    "        char_shifted = sentence_shifted[t]\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "        y[i, t] = char_indices[char_shifted]\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "'''\n",
    "for i in range(0, len(sentences)):\n",
    "    sentence = sentences[i]\n",
    "    for t in range()\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i] = char_indices[next_chars[i]]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18613, 100, 62)\n",
      "(18613,)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " ...\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]]\n",
      "40.0\n"
     ]
    }
   ],
   "source": [
    "print(x[0])\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([40,  0, 44,  ..., 40, 40,  1])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(y).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, hidden_size, layer_dim=1):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.layer_dim = layer_dim\n",
    "        self.lstm1 = nn.LSTM(input_size=num_unique_chars, hidden_size=hidden_size, num_layers=layer_dim, batch_first=True, bidirectional=True, dropout=0.4)\n",
    "        self.fc1 = nn.Linear(hidden_size*2, 50) # hidden_size *2 because of bidirectional\n",
    "        self.fc2 = nn.Linear(50, 50)\n",
    "        self.fc3 = nn.Linear(50, num_unique_chars)\n",
    "        self.dropout = nn.Dropout(p=0.4)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        out, (hn, cn) = self.lstm1(inputs)\n",
    "        hn_flat = torch.cat((hn[0], hn[1]), dim=1)\n",
    "        out = F.relu(self.fc1(hn_flat))\n",
    "        out = self.dropout(out)\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "    \n",
    "net = LSTM(hidden_size=20, layer_dim=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  tensor(4.1467, grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(4.0651, grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(3.8700, grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(3.3345, grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(4.3444, grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(3.3886, grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(3.1984, grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(3.2891, grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(3.3694, grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(3.3942, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(40):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    inputs = torch.from_numpy(x).float()\n",
    "    target = torch.from_numpy(y).long()\n",
    "    \n",
    "    outputs = net(inputs)\n",
    "    #print(outputs.shape)\n",
    "    #print(target.shape)\n",
    "    #print(outputs)\n",
    "    #print(target)\n",
    "    loss = criterion(outputs, target)\n",
    "    \n",
    "    print(\"loss: \", loss)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_next_char(sentence):\n",
    "    #sentence is 40 characters\n",
    "    sentence_preprocess = sentence.replace('\\n', '').replace('<br /><br />', ' ').replace('.', ' .').replace('!', ' !').replace('?', ' ?')\n",
    "    sentence_preprocess = sentence_preprocess.lower()\n",
    "    sentence_trunc = [sentence_preprocess[-40:]]\n",
    "    x = np.zeros((len(sentence_trunc), len(sentence_trunc[0]), len(chars)), dtype=np.bool)\n",
    "    #y = np.zeros((len(sentences)), dtype=np.float)\n",
    "    for i, sentence in enumerate(sentence_trunc):\n",
    "        for t, char in enumerate(sentence):\n",
    "            x[i, t, char_indices[char]] = 1\n",
    "        #y[i] = char_indices[next_chars[i]]\n",
    "    \n",
    "    inputs = torch.from_numpy(x).float()\n",
    "    outputs = net(inputs)\n",
    "    max_indice = torch.argmax(outputs.view(outputs.size(1))).item()\n",
    "    #print(sentence_preprocess)\n",
    "    new_sentence = sentence_preprocess + indices_char[max_indice]\n",
    "    return new_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_generate(sentence, n):\n",
    "    for i in range(n):\n",
    "        sentence = generate_next_char(sentence)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "of three teenage girls at Bromwell High.\n"
     ]
    }
   ],
   "source": [
    "sentence = \"If you like adult comedy cartoons, like South Park, then this is nearly a similar format about the small adventures of three teenage girls at Bromwell High.\"\n",
    "print(sentence[-40:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'if you like adult comedy cartoons, like south park, then this is nearly a similar format about the small adventures of three teenage girls at bromwell high . '"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_next_char(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'if you like adult comedy cartoons, like south park, then this is nearly a similar format about the small adventures of three teenage girls at bromwell high                                                                                                    .                                                                                                    '"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_generate(sentence, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
